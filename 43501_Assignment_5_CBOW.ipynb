{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTItXs2z5O1p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GD1usJJ5O1q"
      },
      "outputs": [],
      "source": [
        "def make_context_vector(context, word_to_ix):\n",
        "    idxs = [word_to_ix[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
        "EMDEDDING_DIM = 100\n",
        "\n",
        "raw_text = \"\"\"In a cozy little cottage nestled on the hillside, a family of mice spent their days\n",
        "            gathering crumbs and telling tales of daring adventures in the wide world beyond. Every evening,\n",
        "            they huddled around the fireplace, where Grandpa Mouse would spin yarns of heroic quests and legendary\n",
        "            cheese heists. Little Timmy Mouse, with wide-eyed wonder, listened intently, dreaming of the day he'd\n",
        "            embark on his very own mouse-sized journey.\"\"\".split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os7w1yZ-5O1r"
      },
      "outputs": [],
      "source": [
        "# By deriving a set from `raw_text`, we duplicate the array\n",
        "vocab = set(raw_text)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "word_to_ix = {word:ix for ix, word in enumerate(vocab)} #make dictonort word and index assign\n",
        "ix_to_word = {ix:word for ix, word in enumerate(vocab)} #made dic index and word\n",
        "\n",
        "data = []\n",
        "for i in range(2, len(raw_text) - 2):\n",
        "    context = [raw_text[i - 2], raw_text[i - 1],\n",
        "               raw_text[i + 1], raw_text[i + 2]]\n",
        "    target = raw_text[i]\n",
        "    data.append((context, target)) #data=data+context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlWuZNiM5O1r"
      },
      "outputs": [],
      "source": [
        "class CBOW(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(CBOW, self).__init__() #\n",
        "\n",
        "        #out: 1 x emdedding_dim for CNN\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(embedding_dim, 128)\n",
        "        self.activation_function1 = nn.ReLU()\n",
        "\n",
        "        #out: 1 x vocab_size\n",
        "        self.linear2 = nn.Linear(128, vocab_size)\n",
        "        self.activation_function2 = nn.LogSoftmax(dim = -1)\n",
        "\n",
        "\n",
        "    def forward(self, inputs): #How to forward pass\n",
        "        embeds = sum(self.embeddings(inputs)).view(1,-1) #normalize 1,-1\n",
        "        out = self.linear1(embeds)\n",
        "        out = self.activation_function1(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.activation_function2(out)\n",
        "        return out\n",
        "\n",
        "    def get_word_emdedding(self, word): #word milali ki index prints\n",
        "        word = torch.tensor([word_to_ix[word]])\n",
        "        return self.embeddings(word).view(1,-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0frgGRw5O1r"
      },
      "outputs": [],
      "source": [
        "model = CBOW(vocab_size, EMDEDDING_DIM)\n",
        "\n",
        "loss_function = nn.NLLLoss()  #negative Log Likelihood Loss\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRn7yHgv5O1r"
      },
      "outputs": [],
      "source": [
        "# Training (for loop)\n",
        "for epoch in range(50):\n",
        "    total_loss = 0\n",
        "\n",
        "    for context, target in data:\n",
        "        context_vector = make_context_vector(context, word_to_ix)\n",
        "\n",
        "        log_probs = model(context_vector)\n",
        "\n",
        "        total_loss += loss_function(log_probs, torch.tensor([word_to_ix[target]]))\n",
        "\n",
        "    # optimize at the end of each epoch\n",
        "    optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCoia6T05O1r",
        "outputId": "0eec5b2b-ab92-45c3-987e-22ff47799d9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw text: In a cozy little cottage nestled on the hillside, a family of mice spent their days gathering crumbs and telling tales of daring adventures in the wide world beyond. Every evening, they huddled around the fireplace, where Grandpa Mouse would spin yarns of heroic quests and legendary cheese heists. Little Timmy Mouse, with wide-eyed wonder, listened intently, dreaming of the day he'd embark on his very own mouse-sized journey.\n",
            "\n",
            "Context: ['where', 'Grandpa', 'would', 'spin']\n",
            "\n",
            "Prediction: Mouse\n"
          ]
        }
      ],
      "source": [
        "# Testing\n",
        "context = ['where', 'Grandpa', 'would','spin']\n",
        "context_vector = make_context_vector(context, word_to_ix)\n",
        "a = model(context_vector)\n",
        "\n",
        "#Print result\n",
        "print(f'Raw text: {\" \".join(raw_text)}\\n')\n",
        "print(f'Context: {context}\\n')\n",
        "print(f'Prediction: {ix_to_word[torch.argmax(a[0]).item()]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCEYe_2Q5O1s"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}